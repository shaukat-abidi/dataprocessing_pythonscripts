{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run it once and Comment\n",
    "# import sys\n",
    "# sys.path.append('C:\\\\Shaukat\\\\code\\\\functions_implemented')\n",
    "# print sys.path\n",
    "# import functions_implemented as fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from copy import deepcopy\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gfs = pd.read_csv(\"C:\\\\Shaukat\\\\code\\\\data_rep\\\\gfs\\\\csv_files\\\\gfs_cygnet.csv\")\n",
    "df_bom = pd.read_csv(\"C:\\\\Shaukat\\\\code\\\\data_rep\\\\bom\\\\Cygnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GFS\n",
    "df_gfs['Unnamed: 0'] = pd.to_datetime(df_gfs['Unnamed: 0'])\n",
    "df_gfs.set_index('Unnamed: 0', inplace = True)\n",
    "\n",
    "# Setting up BOM\n",
    "# df_bom['date_only'] = df_bom.UtcTime.dt.date\n",
    "df_bom.UtcTime = pd.to_datetime(df_bom.UtcTime)\n",
    "df_bom.set_index('UtcTime', inplace=True)\n",
    "\n",
    "# Trim df_bom and df_gfs from november 2016\n",
    "df_bom = df_bom.loc['2016-11-01 00:00:00':]\n",
    "df_gfs = df_gfs.loc['2016-11-01 00:00:00':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gfs.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bom.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare groundtruth dataframe from BOM \n",
    "tot_gfs_entries = len(df_gfs.index)\n",
    "df_gt = pd.DataFrame(index=df_gfs.index, columns=['rainfall_t+1','rainfall_t+2','rainfall_t+3'])\n",
    "for dt_gfs in range(0,tot_gfs_entries):\n",
    "    # Iterate each date in GFS and get the groundtruth rainfall from BOM\n",
    "    \n",
    "    date_a = df_gfs.index[dt_gfs] # Forecast time in gfs (made every three hours)\n",
    "    date_t1 = date_a + timedelta(hours=1) # rainfall_t+1\n",
    "    date_t2 = date_a + timedelta(hours=2) # rainfall_t+2\n",
    "    date_t3 = date_a + timedelta(hours=3) # rainfall_t+3\n",
    "    print 'processing: ', date_a \n",
    "\n",
    "    # df_patch for t+1 (Gather groundtruth rainfall from BOM)\n",
    "    df_patch = df_bom.loc[date_a:date_t1].copy()\n",
    "    rainfall_t1 = df_patch.RainfallLast10Minutes.sum()\n",
    "    print 'date_t1: ', date_t1 \n",
    "\n",
    "    \n",
    "    # df_patch for t+2 (Gather groundtruth rainfall from BOM)\n",
    "    df_patch = df_bom.loc[date_t1:date_t2].copy()\n",
    "    rainfall_t2 = df_patch.RainfallLast10Minutes.sum()\n",
    "    print 'date_t2: ', date_t2 \n",
    "\n",
    "    \n",
    "    # df_patch for t+3 (Gather groundtruth rainfall from BOM)\n",
    "    df_patch = df_bom.loc[date_t2:date_t3].copy()\n",
    "    rainfall_t3 = df_patch.RainfallLast10Minutes.sum()\n",
    "    print 'date_t3: ', date_t3, '\\n' \n",
    "\n",
    "    \n",
    "    # Add it to the groundtruth df\n",
    "    df_gt.loc[date_a] = [rainfall_t1, rainfall_t2, rainfall_t3]\n",
    "    \n",
    "    # Delete variables\n",
    "    del date_a\n",
    "    del date_t1\n",
    "    del date_t2\n",
    "    del date_t3\n",
    "    del rainfall_t1\n",
    "    del rainfall_t2\n",
    "    del rainfall_t3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gt.to_csv(\"check.csv\")\n",
    "# X: df_gfs\n",
    "# Y: df_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_gfs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['pred_cloud_cover', 'pred_cloud_cover_bound_cloud_layer',\n",
    "       'pred_convective_cloud', 'pred_dewp', 'pred_high_tcc',\n",
    "       'pred_low_tcc', 'pred_lw_rad', 'pred_max_wind_press',\n",
    "       'pred_merid_wind', 'pred_middle_tcc', 'pred_rain_rate',\n",
    "       'pred_rel_humidity', 'pred_sunshine', 'pred_surf_geowind', 'pred_surf_momentum_vflux', 'pred_surface_pressure', 'pred_sw_rad',\n",
    "       'pred_temp', 'pred_total_rain', 'pred_ustorm', 'pred_vstorm',\n",
    "       'pred_wind_speed_surf', 'pred_zonal_wind']\n",
    "df_X = df_gfs[col_list].copy()\n",
    "df_Y = df_gt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that df_X is not null\n",
    "df_X_bool = df_X.isnull().any().any()\n",
    "print df_X_bool, 'THIS MUST BE FALSE' # This must be FALSE\n",
    "\n",
    "# df_X.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def prepare_lstm_training_test_set(data_matrix, label_matrix):\n",
    "#     sliding_window = 3\n",
    "#     tot_samples = data_matrix.shape[0]\n",
    "#     sample_dimension = data_matrix.shape[1]\n",
    "#     print \"Total Sample: \",tot_samples\n",
    "#     print \"Dimension of each sample: \",sample_dimension\n",
    "    \n",
    "#     # Accumulate examples here in this list\n",
    "#     input_lstm = []\n",
    "    \n",
    "#     for sequence in range(0,tot_samples-sliding_window):\n",
    "#         input_lstm.append(data_matrix[sequence:sequence+sliding_window, :])\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_matrix = df_X.as_matrix()\n",
    "df_gt_rainfall_forecast_matrix = df_Y.as_matrix()\n",
    "print 'Shape of data matrix: ',df_data_matrix.shape\n",
    "print 'Shape of label matrix: ',df_gt_rainfall_forecast_matrix.shape\n",
    "\n",
    "# Normalize data matrix with zero mean and unit covariance\n",
    "# http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "df_data_matrix = preprocessing.scale(df_data_matrix)\n",
    "\n",
    "data_matrix = np.copy(df_data_matrix)\n",
    "label_matrix = np.copy(df_gt_rainfall_forecast_matrix)\n",
    "\n",
    "sliding_window = 3\n",
    "tot_samples = data_matrix.shape[0]\n",
    "sample_dimension = data_matrix.shape[1]\n",
    "print \"Total Sample: \",tot_samples\n",
    "print \"Dimension of each sample: \",sample_dimension\n",
    "    \n",
    "# Accumulate examples here in this list\n",
    "input_lstm = []\n",
    "label_lstm = []\n",
    "label_entry = sliding_window\n",
    "\n",
    "    \n",
    "for sequence in range(0,tot_samples-sliding_window):\n",
    "    input_lstm.append(data_matrix[sequence:sequence+sliding_window, :])\n",
    "    label_lstm.append(label_matrix[label_entry,0:3])\n",
    "    print \"sequence, sequence+sliding_window, label_entry: \",sequence,sequence+sliding_window,label_entry\n",
    "    label_entry = label_entry + 1\n",
    "\n",
    "\n",
    "return_data_matrix_lstm = np.array(input_lstm)\n",
    "return_label_matrix_lstm = np.array(label_lstm)\n",
    "\n",
    "print \"LSTM input: \",return_data_matrix_lstm.shape\n",
    "print \"LSTM output: \",return_label_matrix_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test and train points\n",
    "tot_points = return_data_matrix_lstm.shape[0]\n",
    "train_points = int(np.floor(0.6*tot_points)) \n",
    "test_points = tot_points - train_points\n",
    "print 'tot_points: ', tot_points, ' train_points: ', train_points, ' test_points: ', test_points\n",
    "\n",
    "# Generate Train Sequence\n",
    "x_train = np.copy(return_data_matrix_lstm[0:train_points + 1,:])\n",
    "y_train = np.copy(return_label_matrix_lstm[0:train_points + 1,:])\n",
    "# Generate Test Sequence\n",
    "x_test = np.copy(return_data_matrix_lstm[train_points + 1:tot_points + 1 ,:])\n",
    "y_test = np.copy(return_label_matrix_lstm[train_points + 1:tot_points + 1 ,:])\n",
    "\n",
    "print 'x_train_shape: ', x_train.shape, ' y_train_shape: ', y_train.shape\n",
    "print 'x_test_shape: ', x_test.shape, ' y_test_shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[2] # Input vector dimension for LSTM (N x timesteps x dim of seq)\n",
    "output_dim = y_train.shape[1] # Output dimension for LSTM (temperature for t+1,t+2,t+3)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "layers = [input_dim, 50, 100, output_dim]\n",
    "\n",
    "model.add(LSTM(input_dim=layers[0],output_dim=layers[1],return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(layers[2], return_sequences=False))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(output_dim=layers[3]))\n",
    "model.add(Activation(\"linear\"))\n",
    "    \n",
    "# compile model\n",
    "# start = time.time()\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "# print \"Compilation Time : \", time.time() - start\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath_savemodel = 'C:\\\\Shaukat\\\\code\\\\rainfall\\\\model_stored\\\\weights.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "filepath_savemodel = 'C:\\\\Shaukat\\\\code\\\\rainfall\\\\model_stored\\\\model_lstm_v2.h5'\n",
    "# filepath_csvlogger = 'C:\\\\Shaukat\\\\code\\\\rainfall\\\\model_stored\\\\training_s2.log'\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath_savemodel, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "# csv_logger = CSVLogger(filepath_csvlogger, separator=',', append=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0.001)\n",
    "\n",
    "# history = model.fit(x_train, y_train, nb_epoch=1000, verbose=1, validation_data=(x_test, y_test), batch_size = 32, shuffle=True, callbacks=[checkpointer, csv_logger, reduce_lr])\n",
    "history = model.fit(x_train, y_train, nb_epoch=500, verbose=1, validation_data=(x_test, y_test), batch_size = train_points, shuffle=True, callbacks=[checkpointer, reduce_lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_test = y_test.flatten()\n",
    "vec_test = vec_test.reshape((len(vec_test),1))\n",
    "print vec_test.shape\n",
    "print 'total test points: ', vec_test.shape[0]\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "pred_vec = predictions.flatten()\n",
    "pred_vec = pred_vec.reshape((len(pred_vec),1))\n",
    "print pred_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess block\n",
    "# threshold = 1.0\n",
    "# preproc_y = deepcopy(pred_vec)\n",
    "# preproc_y[preproc_y<=threshold] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plot\n",
    "time_index = np.arange(0,vec_test.shape[0],1)\n",
    "time_index = time_index.reshape(((len(time_index),1)))\n",
    "\n",
    "plt_lower_limit = 0\n",
    "plt_upper_limit = 100\n",
    "\n",
    "plt.figure(figsize=(25,8))\n",
    "\n",
    "# plot\n",
    "\n",
    "# Full plot\n",
    "# plt.plot(time_index,vec_test,label=\"GroundTruth\",color='b')\n",
    "# plt.plot(time_index,pred_vec,label=\"Prediction\",color='g')\n",
    "\n",
    "# Unpreprocessed Plot\n",
    "plt.plot(time_index[plt_lower_limit:plt_upper_limit],vec_test[plt_lower_limit:plt_upper_limit],label=\"GroundTruth\",color='b')\n",
    "plt.plot(time_index[plt_lower_limit:plt_upper_limit],pred_vec[plt_lower_limit:plt_upper_limit],label=\"Prediction\",color='g')\n",
    "\n",
    "# Preprocessed Plot\n",
    "# plt.plot(time_index[plt_lower_limit:plt_upper_limit],vec_test[plt_lower_limit:plt_upper_limit],label=\"GroundTruth\",color='b')\n",
    "# plt.plot(time_index[plt_lower_limit:plt_upper_limit],preproc_y[plt_lower_limit:plt_upper_limit],label=\"Prediction\",color='g')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Rainfall prediction in mm')\n",
    "plt.legend()\n",
    "plt.title('Groundtruth and Predicted Rainfall per hour')\n",
    "# img_filename = 'C:\\\\Users\\\\ShaukatAbidi\\\\Documents\\\\shaukat_python_progs\\\\learning\\\\time_series\\\\feed_forward_nn\\\\models\\\\s7_images\\\\'+str(test_ex)+'.png'\n",
    "# plt.savefig(img_filename, bbox_inches='tight')\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
